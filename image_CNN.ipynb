{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from skimage import transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def to_gray(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def read_im(folder):\n",
    "    imlist = []\n",
    "    for file in os.listdir(\"data/\" + folder):   #https://stackoverflow.com/questions/72022176/warning-cant-open-read-file-check-file-path-integrity\n",
    "        im = plt.imread(\"data/\" + folder + \"/\"+ file)\n",
    "        im = im[:200,50:250]\n",
    "        im = transform.resize(im, (126, 126), mode='reflect', anti_aliasing=True)  \n",
    "        im= to_gray(im)\n",
    "        #im = im.flatten()\n",
    "        shape = im.shape\n",
    "        imlist.append(im.reshape(1,shape[0], shape[1]))\n",
    "        \n",
    "    images = np.concatenate(imlist, axis =0)\n",
    "    print(f'Reading {folder}: {images.shape}')\n",
    "    return images\n",
    "#generate data labes for images in folders\n",
    "def generate_lables(image_data):\n",
    "   labels = [np.repeat(i,image_data[i].shape[0]) for i in range(len(image_data))]\n",
    "   return np.concatenate(labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"rock\",\"paper\", \"scissors\"]\n",
    "im_data = [read_im(folder) for folder in names]\n",
    "labels = generate_lables(im_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(im_data[0][0].shape)\n",
    "plt.imshow(im_data[0][0])\n",
    "data = np.concatenate(im_data, axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_shape = data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = data.reshape(-1,1,126,126)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "X_train = torch.from_numpy(X_train.reshape(-1,1,126,126))\n",
    "y_train = torch.from_numpy(y_train)\n",
    "X_test = torch.from_numpy(X_test.reshape(-1,1,126,126))\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "classes = (\"rock\", \"paper\", \"scissors\")\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of batches in the training set: {int(len(train_dataset) / batch_size)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size= batch_size,\n",
    "#                                           shuffle = True, num_workers=2)\n",
    "# valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "#                                         shuffle= False, num_workers=2)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "#                                          shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.Cov1 = nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.Cov2 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.Cov3 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3)\n",
    "        self.pool3 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(25088, 512)\n",
    "        self.drop1 = nn.Dropout(p=0.3)\n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=512)\n",
    "        self.drop2 = nn.Dropout(p=0.3)\n",
    "        \n",
    "        self.out = nn.Linear(in_features=512, out_features=3)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.Cov1(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.Cov2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = F.relu(self.Cov3(x))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop1(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.drop2(x)\n",
    "        \n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    print(f'Input shape: {inputs.shape}')\n",
    "    print(f'After network shape: {net(inputs).shape}')\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = 0\n",
    "for x in net.parameters():\n",
    "    num_params += len(torch.flatten(x))\n",
    "    \n",
    "print(f'Number of parameters in the model: {num_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_lst = []\n",
    "acc_lst = []\n",
    "def train_one_epoch():\n",
    "    net.train(True)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    \n",
    "    for batch_index, data in enumerate(train_loader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device) \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs) # shape: [batch_size, 10]\n",
    "        correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "        running_accuracy += correct / batch_size\n",
    "        \n",
    "        loss = criterion(outputs,labels)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_index % 100 == 99:\n",
    "            avg_loss_across_batches = running_loss / 100\n",
    "            avg_acc_across_batches = (running_accuracy / 100) * 100\n",
    "            print('Batch {0}, loss: {1:.3f}, Accuracy: {2:.1f}%'.format(batch_index+1, avg_loss_across_batches,\n",
    "                                                                        avg_acc_across_batches))\n",
    "            loss_lst.append(avg_loss_across_batches)\n",
    "            acc_lst.append(avg_acc_across_batches)\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch():\n",
    "    net.train(False)\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    \n",
    "    for i, data in enumerate(test_loader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = net(inputs)\n",
    "            correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "            running_accuracy += correct / batch_size\n",
    "            loss = criterion(outputs,labels)\n",
    "            running_loss += loss.item()\n",
    "                    \n",
    "    avg_loss_across_batches = running_loss / len(test_loader)\n",
    "    avg_acc_across_batches = (running_accuracy / len(test_loader)) * 100\n",
    "    \n",
    "    print('Val loss: {0: .3f}, Val Accuracy: {1: .1f}%'.format(avg_loss_across_batches,\n",
    "                                                            avg_acc_across_batches))\n",
    "    \n",
    "    print('************************************************************')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch_index in range(num_epochs):\n",
    "    print(f'Epoch: {epoch_index + 1}\\n')\n",
    "    \n",
    "    train_one_epoch()\n",
    "    validate_one_epoch()\n",
    "    \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_CNN = torch.save(net, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# def rotate_image(image, angle):\n",
    "#   \"\"\"Rotates an image by a given angle.\"\"\"\n",
    "#   center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "#   rot_mat = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "#   result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "#   return result\n",
    "\n",
    "# def rotate_dataset(data):\n",
    "#   data = data\n",
    "#   for i in range(len(data)):\n",
    "#     # Generate a random angle between 0 and 360 degrees\n",
    "#     angle = random.randint(0, 360)\n",
    "#     # Rotate the image\n",
    "#     data[i] = rotate_image(data[i], angle)\n",
    "#     # Save the rotated image\n",
    "#     cv2.imwrite(f'processed/rotated_image{i}.jpg', data[i])\n",
    "#   return data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rotate_tensor(tensor_dataset):\n",
    "    \"\"\"\n",
    "    Rotates each image in the tensor dataset randomly by up to 360 degrees.\n",
    "    Preserves the original shape of the dataset.\n",
    "    \n",
    "    Args:\n",
    "        tensor_dataset (torch.Tensor): Input tensor of shape (N, C, H, W)\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Rotated tensor of the same shape as input\n",
    "        \n",
    "    \"\"\"\n",
    "    if isinstance(tensor_dataset, list):\n",
    "        tensor_dataset = torch.tensor(tensor_dataset, dtype=torch.float32)\n",
    "\n",
    "    if not isinstance(tensor_dataset, torch.Tensor):\n",
    "        raise TypeError(\"Input must be a PyTorch tensor or a list convertible to a tensor.\")\n",
    "\n",
    "    N, C, H, W = tensor_dataset.shape\n",
    "    transform = transforms.RandomRotation(degrees=(0, 360))\n",
    "    \n",
    "    rotated_images = torch.zeros_like(tensor_dataset)\n",
    "    \n",
    "    for i in range(N):\n",
    "        rotated_images[i] = transform(tensor_dataset[i])\n",
    "    \n",
    "    return rotated_images\n",
    "rotated_data= random_rotate_tensor(data)\n",
    "rotated_data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
